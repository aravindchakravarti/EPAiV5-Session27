{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BVhNxMW0OIHa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.WARNING,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    force=True\n",
        ")\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for CUDA\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8RACToCeuTm",
        "outputId": "16b9e9d8-1c6a-48e1-cac0-05c3305ab194"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gO_48vCOhH7",
        "outputId": "57c58609-2de4-4ca4-f87f-ad927881ff88"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.58MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 57.3kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:06<00:00, 243kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.96MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(trainloader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "images.shape\n",
        "\n",
        "test_image = images[0].numpy().squeeze()\n",
        "logger.info(f'image shape = {test_image.shape}')\n",
        "plt.imshow(test_image, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "GccFvSXVOt8v",
        "outputId": "cd3ee955-9c2d-4328-a3bd-e6ed708ec9f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class custom_conv_2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
        "        super(custom_conv_2d, self).__init__()\n",
        "\n",
        "        # Handle both int and tuple inputs\n",
        "        if isinstance(kernel_size, int):\n",
        "            kernel_size = (kernel_size, kernel_size)\n",
        "        if isinstance(stride, int):\n",
        "            stride = (stride, stride)\n",
        "        if isinstance(padding, int):\n",
        "            padding = (padding, padding)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "        weight_shape = (out_channels, in_channels, *kernel_size)\n",
        "        weight = torch.empty(weight_shape)\n",
        "        logger.info(f\"weights shape: {weight.shape}\")\n",
        "        nn.init.kaiming_uniform_(weight, a=math.sqrt(5))\n",
        "\n",
        "        # Create trainable parameters\n",
        "        self.weight = nn.Parameter(weight)\n",
        "        self.bias = nn.Parameter(torch.zeros(out_channels)) if bias else None\n",
        "\n",
        "    def _apply_padding(self, x):\n",
        "        if self.padding[0] == 0 and self.padding[1] == 0:\n",
        "            return x\n",
        "\n",
        "        padding_shape = (\n",
        "            x.shape[0],\n",
        "            x.shape[1],\n",
        "            x.shape[2] + 2 * self.padding[0],\n",
        "            x.shape[3] + 2 * self.padding[1]\n",
        "        )\n",
        "        output = torch.zeros(padding_shape, device=x.device)\n",
        "        output[\n",
        "            :,\n",
        "            :,\n",
        "            self.padding[0]:self.padding[0] + x.shape[2],\n",
        "            self.padding[1]:self.padding[1] + x.shape[3]\n",
        "        ] = x\n",
        "\n",
        "        # test_image = output[0].detach().numpy().squeeze()\n",
        "        # print(test_image.shape)\n",
        "        # plt.imshow(test_image, cmap='gray')\n",
        "        # plt.show()\n",
        "\n",
        "\n",
        "        return output\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply padding\n",
        "        x_padded = self._apply_padding(x)\n",
        "\n",
        "        # Calculate output dimensions\n",
        "        height = (x_padded.shape[2] - self.kernel_size[0]) // self.stride[0] + 1\n",
        "        width = (x_padded.shape[3] - self.kernel_size[1]) // self.stride[1] + 1\n",
        "\n",
        "        # Initialize output tensor\n",
        "        output = torch.zeros(x.shape[0], self.out_channels, height, width, device=x.device)\n",
        "\n",
        "        # Perform convolution operation manually\n",
        "        for b in range(x.shape[0]):  # Iterate over batch\n",
        "            for c_out in range(self.out_channels):  # Iterate over output channels\n",
        "                for h in range(height):  # Iterate over height of the output\n",
        "                    h_start = h * self.stride[0]\n",
        "                    for w in range(width):  # Iterate over width of the output\n",
        "                        w_start = w * self.stride[1]\n",
        "\n",
        "                        # Extract the input patch for all input channels\n",
        "                        patch = x_padded[\n",
        "                            b, :,  # Batch\n",
        "                            h_start:h_start + self.kernel_size[0],  # Height slice\n",
        "                            w_start:w_start + self.kernel_size[1]   # Width slice\n",
        "                        ]\n",
        "\n",
        "                        # Perform element-wise multiplication with kernel and sum\n",
        "                        output[b, c_out, h, w] = torch.sum(\n",
        "                            patch * self.weight[c_out]\n",
        "                        )\n",
        "\n",
        "        # Add bias if it exists\n",
        "        if self.bias is not None:\n",
        "            output += self.bias.view(1, -1, 1, 1)\n",
        "\n",
        "        logger.info(f'output shape = {output.shape}')\n",
        "        return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f'in_channels={self.in_channels}, '\n",
        "                f'out_channels={self.out_channels}, '\n",
        "                f'kernel_size={self.kernel_size}, '\n",
        "                f'stride={self.stride}, '\n",
        "                f'padding={self.padding}')"
      ],
      "metadata": {
        "id": "Nli67zi2wSXc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = custom_conv_2d(in_channels=1, out_channels=8, kernel_size=3, padding=True)\n",
        "layer.forward(images[0:2, :, :, :])\n",
        "print(layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STQSUkhZsp3H",
        "outputId": "5f390c20-1718-4046-dea8-63a466d4e55a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in_channels=1, out_channels=8, kernel_size=(3, 3), stride=(1, 1), padding=(True, True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class custom_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(custom_CNN, self).__init__()\n",
        "        self.conv1 = custom_conv_2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = custom_conv_2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)  # 10 classes for MNIST digits\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        logger.info(f\"x shape after 1st conv = {x.shape}\")\n",
        "        logger.info(f\"Completed\")\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        logger.info(f\"x shape after 2nd conv = {x.shape}\")\n",
        "        x = x.view(-1, 64 * 7 * 7)  # Flatten the output\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = custom_CNN().to(device)  # Move model to GPU\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    temp_var = 0\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        temp_var += 1\n",
        "        logger.info(f\"Epoch [{temp_var+1}], Loss: [{running_loss:.4f}]\")\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}\")\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0"
      ],
      "metadata": {
        "id": "aGvtCMsu39SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ideal Code\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Check for CUDA\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the CNN model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)  # 10 classes for MNIST digits\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)  # Flatten the output\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Preprocessing and DataLoader\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = CNN().to(device)  # Move model to GPU\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}\")\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {100 * correct / total:.2f}%')\n",
        "```"
      ],
      "metadata": {
        "id": "yvnPXt2poyuS"
      }
    }
  ]
}